
# LLM 原理與實作全書（大學版，移除公式 × 細節加深）

> **寫作風格**：沿用你 `index.md` 的模式：每節同時提供「**技術版**」與「**白話版**」，並維持段落清晰、重點條列。  
> **深度目標**：大學等級，但**不使用公式**；著重在**工程細節、設計選擇、實務取捨**。  
> **範圍限定**：只談 LLM（大型語言模型），不延伸到視覺或強化學習以外領域。  
> **特別整合**：保留你提供的「**LLM 是在選下一個 token；負向提示會拉高關鍵詞機率**」原文段落，並加入工程對策。

---

## 0. 全文導覽（你可以當作課綱）
1. LLM 本質與心智模型：**自回歸選字**與**接龍**的專業版  
2. Tokenization：BPE/Byte‑BPE、特殊符號、正規化與中文細節  
3. Embedding 與位置：語義座標、位置表示（絕對/相對/旋轉）  
4. Transformer 內部：注意力、殘差、前饋、正規化、遮罩、並行  
5. 訓練資料與流程：清理、去重、打包、優化器、分散式訓練  
6. 微調與對齊：SFT、指令化、PEFT（LoRA/Adapter/QLoRA）、偏好學習（RLHF/DPO）  
7. 推論系統：prefill/decode、KV cache、解碼策略、懲罰與停止條件、服務化  
8. 上下文與長文本：視窗限制、記憶策略、長注意力與外掛記憶  
9. RAG 工程：切段、向量庫、重排序、引用、防幻覺、檢索評估  
10. 效率與成本：量化、蒸餾、稀疏與分片、吞吐與延遲的取捨  
11. 評估與監測：自動指標、人評、紅隊、回歸測試與線上觀測  
12. 常見誤解與安全：負向提示、幻覺、對抗提示、資料隱私  
13. 實務小抄：Prompt 範本、RAG 與 LoRA 清單、除錯手冊

---

## 1. LLM 是什麼？— 自回歸「選下一個字」的系統
### 技術版
- **任務定義**：給定已產生的字串（token 序列），在每個步驟**輸出下一個 token 的機率分布**，再依策略挑一個作為輸出。重複直到結束。  
- **核心特性**：  
  - **條件性**：每一步只依賴「目前看得到的前文」，因此需要**因果遮罩**來禁止偷看未來。  
  - **記憶受限**：一次能看的 token 數（上下文視窗）有限，超過會被截斷或需策略處理。  
  - **統計學派**：它學的是**語言共現與模式**，不是規則清單；故**被文字吸引，不被邏輯約束**。

### 白話版
把 LLM 想成**超會接龍的同學**。你講到什麼，它就被那個「關鍵詞的磁力」吸住，更可能接出**相關**的字，而不是照著「你說不要」就真的**排除**。

> 你的原文補充（完整保留）：
```
LLM 在推論時是在做根據前面所有 token，計算「下一個 token 最可能是誰？」

它不是在心裡跑：「喔，前面有 不要貓，所以我要排除所有跟貓相關的字」。
實際運作比較像：

你輸入：請你回答，不要提到貓，不要提到狗

對模型來說，上下文裡：

貓 這個 token 出現了 1 次

狗 這個 token 出現了 1 次

它學習過的語料裡「提到貓/狗」的句子很多
→ 所以在它的機率分布中，「跟貓狗有關的 token」的機率其實被 拉高 了，而不是變低。

也就是說，它是被文字「吸引」，不是被邏輯「約束」。

模型的思考模式換種說法也可以說是調整後續token機率 
朝更符合prompt的方向調整
```

**工程對策（不要 X 反而越提到 X？）**
- 少用負向提示；改成**正向約束**與**範例**（指定可用詞、格式、風格）。  
- 使用 **logit bias / 禁詞表**、**停止詞**、或**結構化解碼**（JSON Schema/語法約束）來**硬性約束**輸出。  
- 以 **RAG** 或 **工具調用**將答案限制在可信來源；在高風險領域加**人工覆核**。

---

## 2. Tokenization：如何把字變成「可計算的積木」
### 技術版
- **子詞切法主流**：BPE、WordPiece、SentencePiece；多數現代 LLM 使用**Byte‑Level BPE**，連未登錄字與表情也可穩定處理。  
- **正規化與前處理**：大小寫統一、Unicode 正規化（例如全形半形、附加音符處理）、空白壓縮、標點規則化會**影響字典稀疏與長度**。  
- **特殊符號**：
  - **控制/角色標記**（system/user/assistant 等）、**起止符**（BOS/EOS）、**填充符**（PAD）、**未知符**（UNK）。  
  - 這些 token 會參與注意力，影響分段與格式學習。  
- **中文要點**：中文無空白分詞，子詞邊界常落在字、詞中間；外來詞、專名、數字單位（如「5 公里」）的切法會**改變序列長度與可讀性**。  
- **字典大小**：字典太小 → 常見詞被拆太碎，序列拉長；太大 → 訓練與記憶體成本暴漲，且長尾詞仍難涵蓋。  
- **訓練後的再切割**：微調新領域（醫療/法務）若專有名詞很多，可**重新學字典**或**使用附加詞庫**（需考慮兼容性）。

### 白話版
像把一長條麵包切片：切太厚不好咬（新詞吃不下），切太薄很費力（要嚼很久）。好的切法，兼顧**效率**和**能表達原本意思**。

---

## 3. Embedding 與位置資訊：把字放進「語義地圖」
### 技術版
- **Embedding**：每個 token 會被映射到高維向量，隨著上下文經過多層變換而**帶上語境**（同一詞在不同句子可有不同表徵）。  
- **位置資訊**：模型本身不懂順序，需顯式加入：  
  - **絕對位置**：為每個位置加一個固定或可學的向量。  
  - **相對/旋轉位置（如 RoPE 類）**：讓模型更容易**泛化到更長的序列**、並處理「距離」與「方向」資訊。  
- **層內傳遞**：位置訊號會與 token 表徵一起流過每層；不同設計（絕對/相對）會影響**長上下文的穩定度與邊界效應**。  
- **語義距離的應用**：相似度檢索、去重、聚類、主題分群、關鍵句抽取。

### 白話版
想像一張百貨公司地圖：**意思相近**的詞會站在**相近的攤位**；再加上「位置指示牌」，模型才知道誰在前誰在後。

---

## 4. Transformer 內部工學：注意力、殘差、前饋與遮罩
### 技術版
- **注意力（Self‑Attention）**：以**可學投影**把輸入切成查詢、鍵、值三種向量，透過相似度決定要「看誰比較多」，並將多個來源的資訊加權融合。  
- **多頭（Multi‑Head）**：同時學到不同關係（句法、主題、指代、對比等）；不同頭可捕捉不同模式，彼此互補。  
- **前饋網路（FFN / SwiGLU 類）**：在每層注意力後面，用更大的隱層做非線性變換，讓表徵更豐富。  
- **殘差與正規化（Pre‑Norm 趨勢）**：殘差捷徑讓梯度更好傳；正規化位置（層前/層後）影響**訓練穩定與深層可訓性**。  
- **遮罩（Masking）**：  
  - **因果遮罩**：禁止看到未來位置（保證自回歸）。  
  - **填充遮罩**：忽略對齊時的填充符，避免無意義干擾。  
- **複雜度與併行**：注意力在序列長度上是**平方複雜度**；雖然可以在每層並行處理，但長序列成本快速上升。  
- **工程優化**：融合核（fused kernels）、Flash/SDPA 注意力、張量並行與流水線並行、混合精度與檢查點。

### 白話版
想像一堆小手電筒同時照在句子裡的重點字上；每個手電筒偏好不同的重點，最後把「亮的地方」綜合起來。

---

## 5. 訓練資料與流程：從髒數據到可用模型
### 技術版
- **資料來源與治理**：多語多域、授權狀態、隱私去識別、成人/有害文本清理、去重與近重（MinHash/SimHash 類）。  
- **切片與打包**：長文切段避免跨章失真；**動態序列打包**可減少填充浪費、提高吞吐。  
- **教師強迫（Teacher Forcing）**：訓練時每步都餵「正確前文」，讓模型學會在理想前提下預測下一步。  
- **學習率排程**：暖身、平臺、緩慢衰減；配合**權重衰減**與**梯度裁剪**穩定訓練。  
- **優化與精度**：常見 AdamW 類；混合精度訓練（FP16/BF16）降低記憶體與時間；**損失平滑**可抑制過度自信。  
- **分散式訓練**：  
  - **資料並行**：不同卡看不同批次。  
  - **張量並行**：把層內矩陣拆分到多卡。  
  - **流水線並行**：不同層分配到不同卡串接。  
  - **檢查點與容錯**：中斷可恢復；節省記憶體以更深模型。  
- **評估指標**：訓練中常看**困惑度趨勢**與**長上下文穩定性**；離線任務（摘要、問答）則用任務分數。

### 白話版
先把資料**洗乾淨**、**拆合適的段落**、**排好訓練菜單**；再用一群顯卡**分工合作**把大腦練壯。

---

## 6. 微調與對齊：讓模型「像你要的樣子」說話
### 技術版
- **SFT（監督式微調）**：用「輸入→期望輸出」樣本教會格式與任務；資料質比量更重要。  
- **指令化與多任務**：加入角色、語氣與結構指令；混合多任務樣本提升泛化。  
- **PEFT**：
  - **LoRA**：在部分權重旁放**低秩適配器**，只訓練小模組；常見插入點：注意力的查詢/鍵/值/輸出投影、前饋層。  
  - **Adapter**：在每層插入小塊變換，切換任務只換模組。  
  - **QLoRA**：底模量化（省顯存）+ LoRA，**單卡也能做**。  
  - **實務選擇**：先小 rank 試水溫，再按指標拉高；注意**災難性遺忘**與**過度擬合語氣**。  
- **偏好學習（對齊）**：  
  - **RLHF**：標注偏好對比 → 訓練回饋模型 → 以強化方式讓語氣與安全更貼合人類。  
  - **DPO**：不顯式建回饋模型，直接用偏好對比優化，更簡潔、穩定度常較好。  
- **安全規則與防護**：指令白/黑名單、輸出審核器、工具調用沙箱、敏感任務加人審。

### 白話版
把通用的「會說話」大腦，**調成你團隊的口吻與流程**。LoRA 像在原本模型外面「貼小貼紙」，記住任務特別的改動。

---

## 7. 推論與服務化：從 logit 到文字的最後一哩
### 技術版
- **Prefill / Decode**：先把整個提示跑一遍建好**KV cache**，之後逐步生成時只算最後一個步驟，**速度大幅提升**。  
- **解碼策略**：
  - **Greedy / Beam**：穩定、格式好，但容易重複、缺創意；Beam 較適合結構化任務。  
  - **Sampling**：依機率抽樣；**temperature** 控亂度；**top‑k / top‑p** 控候選池。  
  - **懲罰與限制**：**重複/存在懲罰**抑制刷詞；**長度偏置**避免過短或過長；**停止序列**控制收尾。  
  - **可靠度**：高風險任務降低溫度、收窄候選、強制引用。  
- **硬性約束**：  
  - **logit bias** 禁某些詞、偏好某些詞。  
  - **語法/結構化解碼**（JSON Schema、正則/語法樹）保證輸出可解析。  
- **系統層**：批次合併（batching）、請求排程、**流式輸出**、多模型路由、**推測式解碼**提升吞吐。  
- **運維**：觀測 token/s、平均延遲與尾延遲、失敗重試、冷啟/熱身策略。

### 白話版
先把提示「灌進去做暖身」，之後每次只動最後那一格；生成就像**抽籤**，但我們可以把籤筒**管嚴或放鬆**，還能**禁止某些籤**。

---

## 8. 上下文與長文本：讓模型「記得住」
### 技術版
- **視窗限制**：超過視窗就會被截掉；接近邊界的資訊較不穩，尤其在舊式位置編碼上更明顯。  
- **策略**：
  - **滑窗/摘要/分段**：把遠處內容濃縮或帶關鍵段。  
  - **層級式提示**：先總結再詳述，遞進引導。  
  - **長注意力/稀疏注意力**：只讓部分位置互看；或採用**相對/旋轉位置**以提升長度穩定。  
  - **外掛記憶**：RAG、知識庫、工具調用，把關鍵資訊用檢索注入。

### 白話版
像做開會筆記：有限的頁面要**放最重要的重點**；太長就**先摘要**或**再去翻資料**。

---

## 9. RAG 工程設計：讓答案「對齊文件」
### 技術版
- **切段（Chunking）**：以語義或結構為單位；常用重疊以降低「切斷語義」的風險。  
- **嵌入與向量庫**：問題/段落向量化，使用近似最近鄰檢索（ANN）；**混合檢索**（稀疏+稠密）能兼顧關鍵詞與語義。  
- **重排序（Re‑ranking）**：用更精準的模型在 Top‑K 中再挑前幾個，提升命中質量。  
- **提示組裝**：插入「只允許根據以下段落回答」「每句後標來源」等規則；過多段落會擠爆上下文。  
- **引用與防幻覺**：強制**段落‑答案對齊**，回答中**內嵌引用標記**，可選**原文片段回貼**。  
- **檢索評估**：Recall@K、命中率、**審題錯誤**分析；離線與線上 A/B 搭配。  
- **表格/程式碼**：以**結構化查詢**或**工具調用**輔助，避免純語義檢索遺漏數值/欄位。

### 白話版
像寫報告先**找資料**，只准「**用你找到的段落**」寫答案，還要**註明出處**，才不會亂編。

---

## 10. 效率與成本：把模型「養得起、跑得動」
### 技術版
- **量化**：以更低位寬（如 8 位/4 位）近似權重與計算，換取**顯存與速度**；需評估精度損失與校準策略。  
- **蒸餾**：讓小模型學大模型的行為/分布；提升延遲敏感場景的可用性。  
- **分片與並行**：張量/流水線並行、專用加速核、KV cache 壓縮與複用。  
- **路由**：根據任務難度與上下文長度，把請求調度到不同大小/能力的模型以降低成本。  
- **推測式解碼**：用小模型預測一批候選，大模型快速驗證，兼顧**速度與品質**。

### 白話版
把模型想成餐廳：**量化**是把餐具換小一號節省空間，**蒸餾**是把主廚的手藝教給學徒，**路由**是把簡單菜交給小廚房。

---

## 11. 評估與監測：不只分數，更要穩定
### 技術版
- **離線自動評**：任務指標（摘要、問答、翻譯等），加上覆蓋率、格式正確率、citation 完整度。  
- **人評**：多維度（相關、正確、簡潔、禮貌、可操作）；成對比較比單獨打分更穩。  
- **紅隊與安全測試**：越獄、prompt 注入、機密外洩、錯誤工具調用等。  
- **線上監測**：RT/吞吐、出錯碼、超時、平均輸出長度、關鍵詞觸發率；**回歸測試集**避免升級退步。

### 白話版
不是只看分數，還要看**穩不穩、會不會暴走、升級有沒有變差**。

---

## 12. 常見誤解與安全實務
- **「不要提到 X」會生效？** 通常不會。見第 1 節與工程對策。  
- **LLM=事實查詢？** 不是，它是**模式生成器**；要正確請結合 RAG 或工具。  
- **越長越好？** 不一定；長上下文會稀釋焦點、增加成本。  
- **隱私**：避免把個資、商業機密直接塞進公共端點；必要時**本地化**或**脫敏**；日誌與快取也要控管。

---

## 13. 實務小抄（可以直接拿去用）
### 13.1 Prompt 範本
- **角色**：你是嚴謹的技術寫手。  
- **目標**：根據提供段落，輸出「條列重點＋引用來源」。  
- **限制**：不得發揮、不得猜測；若無證據請回答「文件未提及」。  
- **格式**：Markdown；每點 ≤ 30 字；每點後標註段落編號。

### 13.2 RAG 設計清單
- 切段長度、重疊比例、段落標識（ID）；  
- 向量模型與維度、ANN 參數；  
- 重排序模型與輸入長度；  
- Prompt 模板：引用格式、最大段數、拒答規則；  
- 線上指標：命中率、citation 完整度、延遲與失敗率。

### 13.3 LoRA/QLoRA 微調清單
- 插入點（q/k/v/o、ffn 層）、rank 與 α；  
- 量化位寬與校準；  
- 訓練資料來源、格式一致性、覆蓋度評估；  
- 驗收：格式正確率、拒答遵循率、偏好對比勝率。

---

## 14. 總結
- 把 LLM 想成**接龍系統**：每次只是在**選下一個最合理的 token**。  
- 想控制輸出：與其說「不要」，不如**明確給結構、給詞彙、給例子**，必要時**用硬約束**。  
- 想可靠與可追溯：**RAG + 引用**；想便宜：**量化 + LoRA + 路由**；想穩定：**建立回歸測試與線上監控**。

